from urllib.request import urlopen
from six.moves import urllib
from bs4 import BeautifulSoup
import csv
from time import localtime, strftime, mktime
from datetime import datetime
from os.path import exists
import matplotlib.pyplot as plt
import requests
import pandas as pd

headers = {'user-agent': 'Mozilla/5.0 (Macintosh Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',}

html = requests.get(url="https://www.dcard.tw/f/ntub?latest=true", headers=headers).text


bsObj = BeautifulSoup(html,"lxml")

# def getHtml(url):
#     page1=urllib.request.Request(url,headers=headers)
#     page=urllib.request.urlopen(page1)

#     html=page.read()
# ----------------------------------------------
# def get_content(url,headers):
#     '''
#     @获取403禁止访问的网页
#     '''
#     randdom_header=random.choice(headers)
    
#     req=urllib2.Request(url)
#     req.add_header("User-Agent",randdom_header)
#     req.add_header("Host","https://www.dcard.tw/f/ntub?latest=true")
#     req.add_header("Referer","http://blog.csdn.net/")
#     req.add_header("GET",url)
    
#     content=urllib2.urlopen(req).read()
#     return content




for single_tr in bsObj.find("div",{"class":"PostList_entry_1rq5Lf"}).findAll("div",{"class":"PostEntry_content_g2afgv"}):
    cell = single_tr.findAll("article")
    currency_name = cell[0].find("h3",{"class":"PostEntry_title_H5o4dj PostEntry_unread_2U217-"})#.contents[0]
    print(currency_name)
    currency_name = currency_name.replace("\r","")
    currency_name = currency_name.replace("\n","")
    currency_name = currency_name.replace(" ","")
#     currency_time = cell[2].contents[0]
    print("#",single_tr+1)
    print(currency_name)
    file_name = "dcard" + currency_name+ ".csv"
    now_time = strftime("%Y-%m-%d %H:%M:%S", localtime())
    if not exists(file_name):
        data = [['時間'],[now_time]]
    else:
        data=[[now_time]]
        f=open(file_name,"a")
        w= csv.writer(f)
        w.writerows(data)
        f.close()

for index,title,excerpt,time in enumerate(title,excerpt,time):
    data = {"title":"%s" % title,"excerpt":"%s" % excerpt, "createdAt":"%s"% time}
    res = requests.post('https://www.dcard.tw/f/ntub?latest=true', data=data)
    if index == 0:
        article = pd.read_html(res.text, header=0)[0]
        article['title'] = title
    if index > 0:
        article_= pd.read_html(res.text, header=0)[0]
        article_['title'] = title
        article = article.append(article_)
    print('%2d)%-*s%4d'% (index+1,5,title,pd.read_html(res.text,header=0)[0].shape[0]))
article.to_excel('Dcard_article.xlsx',encoding="UTF-8",index=False)
